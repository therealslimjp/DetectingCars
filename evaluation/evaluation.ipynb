{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7531513,
     "sourceType": "datasetVersion",
     "datasetId": 4386606
    },
    {
     "sourceId": 7499349,
     "sourceType": "datasetVersion",
     "datasetId": 4360256
    }
   ],
   "dockerImageVersionId": 30648,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "def calculate_intersect_union(pred, target):\n",
    "    # calculate intersection and union\n",
    "    intersection = np.logical_and(target, pred)\n",
    "    union = np.logical_or(target, pred)\n",
    "\n",
    "    return intersection, union\n",
    "\n",
    "def calculate_iou(intersection, union):\n",
    "    # calculate intersection over union\n",
    "    return np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "    # calculate accuracy\n",
    "    return np.sum(pred == target) / np.prod(target.shape)\n",
    "\n",
    "def calculate_dice(intersection, union):\n",
    "    # calculate dice coefficient\n",
    "    return 2 * np.sum(intersection) / (np.sum(union) + np.sum(intersection)) if np.sum(union) != 0 else 0\n",
    "\n",
    "def iou(pred, target):\n",
    "    # calculate intersection and union\n",
    "    intersection, union = calculate_intersect_union(pred, target)\n",
    "    # calculate intersection over union\n",
    "    return calculate_iou(intersection, union)\n",
    "\n",
    "def dice(pred, target):\n",
    "    # calculate intersection and union\n",
    "    intersection, union = calculate_intersect_union(pred, target)\n",
    "    # calculate dice coefficient\n",
    "    return calculate_dice(intersection, union)\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    # calculate accuracy\n",
    "    return calculate_accuracy(pred, target)\n",
    "\n",
    "def compute_all(pred, target):\n",
    "\n",
    "    # Calculate metrics using numpy arrays\n",
    "    iou_value = iou(pred, target)\n",
    "    dice_value = dice(pred, target)\n",
    "    accuracy_value = accuracy(pred, target)\n",
    "\n",
    "    metrics = {\n",
    "        \"IoU\": iou_value,\n",
    "        \"Dice\": dice_value,\n",
    "        \"Accuracy\": accuracy_value,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def compute_all(pred, target):\n",
    "\n",
    "    # Calculate metrics using numpy arrays\n",
    "    iou_value = iou(pred, target)\n",
    "    dice_value = dice(pred, target)\n",
    "    accuracy_value = accuracy(pred, target)\n",
    "\n",
    "    metrics = {\n",
    "        \"IoU\": iou_value,\n",
    "        \"Dice\": dice_value,\n",
    "        \"Accuracy\": accuracy_value,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "         # turn into Numpy arrays\n",
    "        pred_label = np.array(pred_labels)\n",
    "        label = np.array(labels)\n",
    "        \n",
    "        return compute_all(pred_label, label)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T15:49:44.375705Z",
     "iopub.execute_input": "2024-02-01T15:49:44.376094Z",
     "iopub.status.idle": "2024-02-01T15:49:44.391175Z",
     "shell.execute_reply.started": "2024-02-01T15:49:44.376059Z",
     "shell.execute_reply": "2024-02-01T15:49:44.390102Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRANSFORMER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_files_filtered(path, name = \"img.jpg\"):\n",
    "    image_files = []\n",
    "    for file in find_files_by_pattern(path, name):\n",
    "        # get npy file\n",
    "        npy_path = os.path.join(os.path.dirname(file), \"label.npy\")\n",
    "        array = np.load(npy_path)\n",
    "        if np.sum(array) > 0:\n",
    "            image_files.append(file)\n",
    "    return image_files\n",
    "\n",
    "def get_files_all(path, name = \"img.jpg\"):\n",
    "    image_files = []\n",
    "    for file in find_files_by_pattern(path, name):\n",
    "        \n",
    "        image_files.append(file)\n",
    "        \n",
    "    return image_files"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T15:44:48.269098Z",
     "iopub.execute_input": "2024-02-01T15:44:48.269414Z",
     "iopub.status.idle": "2024-02-01T15:44:48.284838Z",
     "shell.execute_reply.started": "2024-02-01T15:44:48.269386Z",
     "shell.execute_reply": "2024-02-01T15:44:48.283918Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer_model=SegformerForSemanticSegmentation.from_pretrained(\"/kaggle/input/tds-models/TDS_Models/best_model_transformer\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T16:16:18.137493Z",
     "iopub.execute_input": "2024-02-01T16:16:18.137854Z",
     "iopub.status.idle": "2024-02-01T16:16:19.144809Z",
     "shell.execute_reply.started": "2024-02-01T16:16:18.137826Z",
     "shell.execute_reply": "2024-02-01T16:16:19.143721Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, DatasetDict, Image\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"car_segmentation\",\n",
    "    learning_rate=6e-5,\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_total_limit=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_Dice'\n",
    ")\n",
    "\n",
    "# Evaluating transformer \n",
    "folder_path = '/kaggle/input/car-street-data/train_test_split_car'\n",
    "\n",
    "train_img_files = list(get_files_filtered(folder_path + \"/train\", 'img.jpg'))\n",
    "train_label_files = list(get_files_filtered(folder_path + \"/train\", 'label.png'))\n",
    "\n",
    "test_img_files = list(get_files_filtered(folder_path + \"/test\", 'img.jpg'))\n",
    "test_label_files = list(get_files_filtered(folder_path + \"/test\", 'label.png'))\n",
    "\n",
    "valid_img_files = list(get_files_filtered(folder_path + \"/validation\", 'img.jpg'))\n",
    "valid_label_files = list(get_files_filtered(folder_path + \"/validation\", 'label.png'))\n",
    "def create_dataset(image_paths, label_paths):\n",
    "    dataset = Dataset.from_dict({\"image\": sorted(image_paths),\n",
    "                                \"label\": sorted(label_paths)})\n",
    "    dataset = dataset.cast_column(\"image\", Image())\n",
    "    dataset = dataset.cast_column(\"label\", Image())\n",
    "\n",
    "    return dataset\n",
    "train_dataset = create_dataset(train_img_files, train_label_files)\n",
    "test_dataset = create_dataset(test_img_files, test_label_files)\n",
    "valid_dataset = create_dataset(valid_img_files, valid_label_files)\n",
    "dataset = DatasetDict({'train': train_dataset, 'test': test_dataset, 'valid': valid_dataset})\n",
    "\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(height=500, width=500),\n",
    "])\n",
    "\n",
    "def preprocess_val_test(examples):\n",
    "    augmented_pixel_values = []\n",
    "    augmented_labels = []\n",
    "    for i in range(len(examples[\"image\"])):\n",
    "        augmented = val_transforms(image=np.array(examples[\"image\"][i]), mask=np.array(examples[\"label\"][i]))\n",
    "        \n",
    "        # Convert to PyTorch tensors and floats\n",
    "        pixel_values = torch.tensor(augmented[\"image\"], dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        labels = torch.tensor(augmented[\"mask\"], dtype=torch.long)\n",
    "        \n",
    "        augmented_pixel_values.append(pixel_values)\n",
    "        augmented_labels.append(labels)\n",
    "\n",
    "    return {\"pixel_values\": augmented_pixel_values, \"labels\": augmented_labels}\n",
    "\n",
    "dataset[\"valid\"].set_transform(preprocess_val_test)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T15:50:25.947487Z",
     "iopub.execute_input": "2024-02-01T15:50:25.948354Z",
     "iopub.status.idle": "2024-02-01T15:50:34.137356Z",
     "shell.execute_reply.started": "2024-02-01T15:50:25.948326Z",
     "shell.execute_reply": "2024-02-01T15:50:34.136494Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=transformer_car.model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"] ,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.evaluate(dataset[\"valid\"])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T15:50:34.139175Z",
     "iopub.execute_input": "2024-02-01T15:50:34.139942Z",
     "iopub.status.idle": "2024-02-01T15:51:51.626879Z",
     "shell.execute_reply.started": "2024-02-01T15:50:34.139911Z",
     "shell.execute_reply": "2024-02-01T15:51:51.625679Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:03]\n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
     "output_type": "stream"
    },
    {
     "output_type": "stream",
     "name": "stdin",
     "text": "  ········································\n"
    },
    {
     "name": "stderr",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240201_155120-b9xfse5u</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/enterpriseai/huggingface/runs/b9xfse5u' target=\"_blank\">glorious-totem-9</a></strong> to <a href='https://wandb.ai/enterpriseai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/enterpriseai/huggingface' target=\"_blank\">https://wandb.ai/enterpriseai/huggingface</a>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/enterpriseai/huggingface/runs/b9xfse5u' target=\"_blank\">https://wandb.ai/enterpriseai/huggingface/runs/b9xfse5u</a>"
     },
     "metadata": {}
    },
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'eval_loss': 0.005484578665345907,\n 'eval_IoU': 0.6594682992284469,\n 'eval_Dice': 0.7947946936197094,\n 'eval_Accuracy': 0.99796975,\n 'eval_runtime': 4.5824,\n 'eval_samples_per_second': 10.475,\n 'eval_steps_per_second': 2.619}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FAST AI CAR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to count .npy files with sum > 0\n",
    "def count_files_with_sum_gt_zero(folder):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                array = np.load(file_path)\n",
    "                if np.sum(array) > 0:\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def find_files_by_pattern(folder, pattern):\n",
    "    matching_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(pattern):\n",
    "                matching_files.append(root + \"/\" + file)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "def get_images_filtered(name):\n",
    "    image_files = []\n",
    "    for file in find_files_by_pattern(folder_path, \"img.jpg\"):\n",
    "        # get npy file\n",
    "        npy_path = os.path.join(os.path.dirname(file), \"label.npy\")\n",
    "        array = np.load(npy_path)\n",
    "        if np.sum(array) > 0:\n",
    "            image_files.append(Path(file))\n",
    "    return image_files\n",
    "\n",
    "def get_images_all(name):\n",
    "    image_files = []\n",
    "    for file in find_files_by_pattern(folder_path, \"img.jpg\"):\n",
    "        image_files.append(Path(file))\n",
    "    return image_files\n",
    "\n",
    "# define a function to get the numpy mask for the given path\n",
    "def get_mask(path):\n",
    "    #remove the file name and extension from the path\n",
    "    path = path.parent \n",
    "    # add the name mask.npy to the path\n",
    "    path = path.joinpath(\"label.npy\")\n",
    "    return np.load(path)\n",
    "\n",
    "aerial_Block_all = DataBlock(blocks = (ImageBlock, MaskBlock(codes = [\"nothing\",\"car\"])),\n",
    "                            splitter=GrandparentSplitter(train_name='train', valid_name='validation'),\n",
    "                            get_items=get_images_all,\n",
    "                            get_y=get_mask,\n",
    "                            batch_tfms=aug_transforms(size=500, max_lighting=0.3))\n",
    "\n",
    "dataloader_all = aerial_Block_all.dataloaders(\"./\",bs=8)\n",
    "\n",
    "# define functions to calculate desired metrics\n",
    "def convert_preds_and_target(pred, target):\n",
    "    # convert predictions to numpy array with max probability index\n",
    "    pred = pred.argmax(dim=1).cpu().numpy()\n",
    "    # convert target to numpy array\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    return pred, target\n",
    "\n",
    "def calculate_intersect_union(pred, target):\n",
    "    # calculate intersection and union\n",
    "    intersection = np.logical_and(target, pred)\n",
    "    union = np.logical_or(target, pred)\n",
    "\n",
    "    return intersection, union\n",
    "\n",
    "def calculate_iou(intersection, union):\n",
    "    # calculate intersection over union\n",
    "    return np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 1\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "    # calculate accuracy\n",
    "    return np.sum(pred == target) / np.prod(target.shape)\n",
    "\n",
    "def calculate_dice(intersection, union):\n",
    "    # calculate dice coefficient\n",
    "    return 2 * np.sum(intersection) / (np.sum(union) + np.sum(intersection)) if np.sum(union) != 0 else 1\n",
    "\n",
    "def iou(pred, target):\n",
    "    # convert predictions and target to numpy arrays\n",
    "    pred, target = convert_preds_and_target(pred, target)\n",
    "    # calculate intersection and union\n",
    "    intersection, union = calculate_intersect_union(pred, target)\n",
    "    # calculate intersection over union\n",
    "    return calculate_iou(intersection, union)\n",
    "\n",
    "def dice(pred, target):\n",
    "    # convert predictions and target to numpy arrays\n",
    "    pred, target = convert_preds_and_target(pred, target)\n",
    "    # calculate intersection and union\n",
    "    intersection, union = calculate_intersect_union(pred, target)\n",
    "    # calculate dice coefficient\n",
    "    return calculate_dice(intersection, union)\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    # convert predictions and target to numpy arrays\n",
    "    pred, target = convert_preds_and_target(pred, target)\n",
    "    # calculate accuracy\n",
    "    return calculate_accuracy(pred, target)\n",
    "\n",
    "learner_all = unet_learner(dataloader_all,resnet34,metrics=[dice, iou, accuracy])\n",
    "learner_all.load('/kaggle/input/tds-models/TDS_Models/best_model_car')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T16:21:48.452237Z",
     "iopub.execute_input": "2024-02-01T16:21:48.452581Z",
     "iopub.status.idle": "2024-02-01T16:21:52.936981Z",
     "shell.execute_reply.started": "2024-02-01T16:21:48.452554Z",
     "shell.execute_reply": "2024-02-01T16:21:52.935943Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": [
    {
     "execution_count": 53,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<fastai.learner.Learner at 0x7d405bddc460>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = learner_all.validate(1)\n",
    "print(f\"Results: {results}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T16:22:42.316703Z",
     "iopub.execute_input": "2024-02-01T16:22:42.317077Z",
     "iopub.status.idle": "2024-02-01T16:22:52.070316Z",
     "shell.execute_reply.started": "2024-02-01T16:22:42.317048Z",
     "shell.execute_reply": "2024-02-01T16:22:52.069105Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Results: [0.0013204907299950719, 0.7299018651494741, 0.617853217955704, 0.9995285263157893]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to count .npy files with sum > 0\n",
    "def count_files_with_sum_gt_zero(folder):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                array = np.load(file_path)\n",
    "                if np.sum(array) > 0:\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def find_files_by_pattern(folder, pattern):\n",
    "    matching_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(pattern):\n",
    "                matching_files.append(root + \"/\" + file)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "def get_images_filtered(name):\n",
    "    image_files = []\n",
    "    for file in find_files_by_pattern(folder_path, \"img.jpg\"):\n",
    "        # get npy file\n",
    "        npy_path = os.path.join(os.path.dirname(file), \"label.npy\")\n",
    "        array = np.load(npy_path)\n",
    "        if np.sum(array) > 0:\n",
    "            image_files.append(Path(file))\n",
    "    return image_files\n",
    "\n",
    "def get_images_all(name):\n",
    "    image_files = []\n",
    "    for file in find_files_by_pattern(folder_path, \"img.jpg\"):\n",
    "        image_files.append(Path(file))\n",
    "    return image_files\n",
    "\n",
    "# define a function to get the numpy mask for the given path\n",
    "def get_mask(path):\n",
    "    #remove the file name and extension from the path\n",
    "    path = path.parent \n",
    "    # add the name mask.npy to the path\n",
    "    path = path.joinpath(\"label_street_mask.npy\")\n",
    "    return np.load(path)\n",
    "\n",
    "aerial_Block_all = DataBlock(blocks = (ImageBlock, MaskBlock(codes = [\"nothing\",\"car\"])),\n",
    "                            splitter=GrandparentSplitter(train_name='train', valid_name='validation'),\n",
    "                            get_items=get_images_all,\n",
    "                            get_y=get_mask,\n",
    "                            batch_tfms=aug_transforms(size=500, max_lighting=0.3))\n",
    "\n",
    "dataloader_all = aerial_Block_all.dataloaders(\"./\",bs=8)\n",
    "\n",
    "# define functions to calculate desired metrics\n",
    "def convert_preds_and_target(pred, target):\n",
    "    # convert predictions to numpy array with max probability index\n",
    "    pred = pred.argmax(dim=1).cpu().numpy()\n",
    "    # convert target to numpy array\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    return pred, target\n",
    "\n",
    "def calculate_intersect_union(pred, target):\n",
    "    # calculate intersection and union\n",
    "    intersection = np.logical_and(target, pred)\n",
    "    union = np.logical_or(target, pred)\n",
    "\n",
    "    return intersection, union\n",
    "\n",
    "def calculate_iou(intersection, union):\n",
    "    # calculate intersection over union\n",
    "    return np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 1\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "    # calculate accuracy\n",
    "    return np.sum(pred == target) / np.prod(target.shape)\n",
    "\n",
    "def calculate_dice(intersection, union):\n",
    "    # calculate dice coefficient\n",
    "    return 2 * np.sum(intersection) / (np.sum(union) + np.sum(intersection)) if np.sum(union) != 0 else 1\n",
    "\n",
    "def iou(pred, target):\n",
    "    # convert predictions and target to numpy arrays\n",
    "    pred, target = convert_preds_and_target(pred, target)\n",
    "    # calculate intersection and union\n",
    "    intersection, union = calculate_intersect_union(pred, target)\n",
    "    # calculate intersection over union\n",
    "    return calculate_iou(intersection, union)\n",
    "\n",
    "def dice(pred, target):\n",
    "    # convert predictions and target to numpy arrays\n",
    "    pred, target = convert_preds_and_target(pred, target)\n",
    "    # calculate intersection and union\n",
    "    intersection, union = calculate_intersect_union(pred, target)\n",
    "    # calculate dice coefficient\n",
    "    return calculate_dice(intersection, union)\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    # convert predictions and target to numpy arrays\n",
    "    pred, target = convert_preds_and_target(pred, target)\n",
    "    # calculate accuracy\n",
    "    return calculate_accuracy(pred, target)\n",
    "\n",
    "learner_all_street = unet_learner(dataloader_all,resnet34,metrics=[dice, iou, accuracy])\n",
    "learner_all_street.load('/kaggle/input/tds-models/TDS_Models/best_model_street')\n",
    "learner_all_street.validate(1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-01T16:24:01.478089Z",
     "iopub.execute_input": "2024-02-01T16:24:01.478468Z",
     "iopub.status.idle": "2024-02-01T16:24:16.443755Z",
     "shell.execute_reply.started": "2024-02-01T16:24:01.478437Z",
     "shell.execute_reply": "2024-02-01T16:24:16.442735Z"
    },
    "trusted": true
   },
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/fastai/learner.py:59: UserWarning: Saved file doesn't contain an optimizer state.\n  elif with_opt: warn(\"Saved file doesn't contain an optimizer state.\")\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    },
    {
     "execution_count": 56,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(#4) [0.04600682109594345,0.7963414279794532,0.6859894095144277,0.9834106947368421]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
